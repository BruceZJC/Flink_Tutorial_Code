# 独立笔记 - Flink 流处理 API

## Environment

### getExecutionEnvironment

创建一个执行环境，表时当前执行程序的上下文。如果程序是独立调用的，则此方法返回本地执行环境；如果从命令行客户端调用程序以提交到集群，则此方法返回此集群的执行环境。也就是说 getExecutionEnvironment 会根据 查询运行的方式 决定返回什么样的运行环境

### createLocalEnvironment

返回本地执行环境，需要在调用的时候指定默认的并行度

```java
LocalStreamEnvironment env = StreamExecutionEnvironment.createLocalEnvironment(1)；
```

### createRemoteEnvironment

返回集群执行环境，将 Jar 包提交到远程服务器。需要在调用时指定 Jobmanager 的 IP 和端口号，并指定要在集群运行的 Jar 包

```java
StreamExecutionEnvironment env = 
StreamExecutionEnvironment.createRemoteEnvironment("jobmanage-hostname",
####,
"path/xxxx.jar");
```

## Source  从外部读取数据

### 从集合读取数据

```java
DataStream<SensorReading> dataStream = env.fromCollection(
                Arrays.asList(
                        new SensorReading("sensor_1", 153411411L, 15.1),
                        new SensorReading("sensor_2", 153411572L, 15.2),
                        new SensorReading("sensor_3", 153418123L, 15.3),
                        new SensorReading("sensor_4", 150938434L, 15.4)
                )
        );
//或者是
DataStream<Integer> integerDataStreamSource = env.fromElements(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);
```

### 从文件中读取数据

```java
 DataStream<String> dataStream = env.readTextFile("C:\\Users\\86173\\IdeaProjects\\practice\\src\\main\\resources\\sensor.txt");
```

### 从Kafka读取数据

```java
properties.setProperty("bootstrap.servers","localhost:9092");
//properties.setProperty("group.id","consumer-group");
//properties.setProperty("auto.offset.rest","latest");
DataStream<String> dataStream = 
env.addSource(new FlinkKafkaConsumer<String>("test",new SimpleStringSchema(),properties));
```

## Transform 转换算子

### map

最简单的数据处理方式，进来一个数据处理一个数据

```java
DataStream<Integer> mapStream = dataStream.map( new MapFunction<String, Integer>(){
   public Integer map(String value) throws Exception{
      return value.length();
   }
});
```

### flatMap

将数据打散，做拆分；进入一个数据可以输出多个数据

```java
DataStream<String> flatMapStream = dataStream.flatMap( new FlatMapFunction<String,
 String>(){
   public void flatMap(String value, Collector<String> out) throws Exception{
      String[] fields = value.split(',');
      for(String field: fields){
        out.collect(field);
      }
   }
});
```

### filter

将进入的数据以某种条件进行筛选，有可能输出，有可能不输出

```java
DataStream<String> filterStream = inputStream.filter(new FilterFunction<String>() {
            @Override
            public boolean filter(String value) throws Exception {
                return value.startsWith("sensor_1");
            }
        });
```

## Transform 聚合算子

### KeyBy

流无法直接做聚合操作，需要先通过keyBy分组，得到一个Keyed Stream。严格意义上不算是一个计算过程，只是将一个 流 拆分成多个不相交的分区。多个不同的key可以被分配到同一个分区

### Rolling Aggregation 滚动聚合算子

这些算子可以针对 Keyed Stream的每一个支流做聚合操作

- sum( )
- min( )
- max( )
- minBy( ) 同时还返回与min（）对应的其他信息
- maxBy( )

### Reduce

Keyed Stream → DataStream, 一个分组数据流的聚合操作，合并 当前的元素 和 上次聚合的结果，产生一个新的值。返回的流包括每一次聚合的结果，而不是只返回最后一次聚合的结果。

Reduce 之后不改变数据类型

```java
keyedStream.reduce(new ReduceFunction<SensorReading>() {
       @Override
       public SensorReading reduce(SensorReading value1, SensorReading value2) throws Exception {
           return new SensorReading(value1.getId(), value2.getTimeStamp(), Math.max(value1.getTemperature(), value2.getTemperature()));
       }
});
```

## Transform 多流转换算子

### Split  和 Select（Deprecated）

DataStream → SplitStream，根据某些特征把一个 DataStream 拆分成两个或多个 DataStream.

### Connect 和 CoMap

DataStream, DataStream → ConnectedStream。连接两个保持他们类型的数据流，两个数据流被 connect 之后，只是被放在了同一个流中，内部依然保持各自的数据和形式不发生任何变化，两个流互相独立

[Split, Select, Connect, CoMap](%E7%8B%AC%E7%AB%8B%E7%AC%94%E8%AE%B0%20-%20Flink%20%E6%B5%81%E5%A4%84%E7%90%86%20API%20903b78e1da6e473896b6f14d497365f9/Split,%20Select,%20Connect,%20CoMap%20edd73912cebd4f739dd40c97c41e5c49.md)

### Union

DataStream (s) → DataStream 对两个或者两个以上的 DataStream 进行 Union 操作，产生一个包含所有 DataStream 元素的新 DataStream。被 Union 的流的数据类型必须是一样的

## Sink 输出到外部系统

dataStream.addSink( )

## Window 概念

Window 就是将无限流切割为有限流进行计算的一种方式，它会将流数据分发到有限大小的 Bucket 中进行分析

![Untitled](%E7%8B%AC%E7%AB%8B%E7%AC%94%E8%AE%B0%20-%20Flink%20%E6%B5%81%E5%A4%84%E7%90%86%20API%20903b78e1da6e473896b6f14d497365f9/Untitled.png)

## Window 类型

### Time Window 时间窗口

1. ( Tumbling Window )滚动时间窗口

![Untitled](%E7%8B%AC%E7%AB%8B%E7%AC%94%E8%AE%B0%20-%20Flink%20%E6%B5%81%E5%A4%84%E7%90%86%20API%20903b78e1da6e473896b6f14d497365f9/Untitled%201.png)

- 将数据依据固定的窗口长度对比数据进行切分
- 时间对齐，窗口长度固定，没有重叠。压线的数据属于后一个窗口
1. ( Sliding Window )滑动时间窗口

![Untitled](%E7%8B%AC%E7%AB%8B%E7%AC%94%E8%AE%B0%20-%20Flink%20%E6%B5%81%E5%A4%84%E7%90%86%20API%20903b78e1da6e473896b6f14d497365f9/Untitled%202.png)

- 滑动窗口是固定窗口的更广义的一种形式，滑动窗口由固定的窗口长度和滑动间隔组成
- 窗口长度固定，可以有重叠
1. ( Session Window )会话窗口

![Untitled](%E7%8B%AC%E7%AB%8B%E7%AC%94%E8%AE%B0%20-%20Flink%20%E6%B5%81%E5%A4%84%E7%90%86%20API%20903b78e1da6e473896b6f14d497365f9/Untitled%203.png)

- 由一系列事件组合一个指定时间长度的 timeout 间隙组成，也就是一段时间内没有接收新的数据就会生成新的窗口。session gap是规定的最小的间隔
- 特点是 时间无对齐

### Count Window 计数窗口

计数窗口只有以下两种：

- 滚动计数窗口（ Tumbling ）
- 滑动计数窗口（ Sliding ）

## Window API

- 我们可以用 .window( ) 来定义一个窗口，然后基于这个window去做一些聚合或者其他处理操作注意window()方法必须在keyBy之后才能使用。
- Flink提供了更加简单的 .timeWindow( ) 和 .countWindow( ) 方法，用于定义时间窗口和计数窗口

```java
DataStream<Tuple2<String,Double>> minTempPerWindowStream = 
  datastream
  .map(new MyMapper())
  .keyBy(data -> data.f0)
  .window(TumblingProcessingTimeWindows.of(Time.seconds(15)))
  .minBy(1);
//使用 Window 的例子
```

- windows( ) 方法接收的参数是一个 WidnowAssigner，负责将每条输入的数据分发到正确的 Window 中。
- 创建 计数窗口（Count Window）有一个较为方便的方式为调用 .countWindow( )，相比 .window( )

### Window Function 窗口函数

Window Fucntion 定义了要对窗口中收集的数据做的计算操作，分为两类：

- 增量聚合函数（ Incremental Aggregation Functions ）

       每条数据到来就进行计算，保持一个简单的状态

       ReduceFunction，AggregateFunction

- 全窗口函数（ Full Window Function，有点类似 Spark 的批处理 ）

       先把窗口所有的数据收集起来，等到计算的时候会遍历所有数据

       ProcessWindowFunction（ .process( ) ），WindowFunction

[sensor.txt](%E7%8B%AC%E7%AB%8B%E7%AC%94%E8%AE%B0%20-%20Flink%20%E6%B5%81%E5%A4%84%E7%90%86%20API%20903b78e1da6e473896b6f14d497365f9/sensor.txt)

[WindowTest1_TimeWindow.java](%E7%8B%AC%E7%AB%8B%E7%AC%94%E8%AE%B0%20-%20Flink%20%E6%B5%81%E5%A4%84%E7%90%86%20API%20903b78e1da6e473896b6f14d497365f9/WindowTest1_TimeWindow.java)